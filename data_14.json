{"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/14", "repository_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning", "labels_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/14/labels{/name}", "comments_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/14/comments", "events_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/14/events", "html_url": "https://github.com/PyTorchLightning/pytorch-lightning/issues/14", "id": 471725152, "node_id": "MDU6SXNzdWU0NzE3MjUxNTI=", "number": 14, "title": "Arbitrary lr_scheduler?", "user": {"login": "lkhphuc", "id": 12573521, "node_id": "MDQ6VXNlcjEyNTczNTIx", "avatar_url": "https://avatars.githubusercontent.com/u/12573521?v=4", "gravatar_id": "", "url": "https://api.github.com/users/lkhphuc", "html_url": "https://github.com/lkhphuc", "followers_url": "https://api.github.com/users/lkhphuc/followers", "following_url": "https://api.github.com/users/lkhphuc/following{/other_user}", "gists_url": "https://api.github.com/users/lkhphuc/gists{/gist_id}", "starred_url": "https://api.github.com/users/lkhphuc/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/lkhphuc/subscriptions", "organizations_url": "https://api.github.com/users/lkhphuc/orgs", "repos_url": "https://api.github.com/users/lkhphuc/repos", "events_url": "https://api.github.com/users/lkhphuc/events{/privacy}", "received_events_url": "https://api.github.com/users/lkhphuc/received_events", "type": "User", "site_admin": false}, "labels": [], "state": "closed", "locked": false, "assignee": null, "assignees": [], "milestone": null, "comments": 5, "created_at": "2019-07-23T14:18:23Z", "updated_at": "2019-07-28T13:58:13Z", "closed_at": "2019-07-28T13:58:13Z", "author_association": "NONE", "active_lock_reason": null, "body": "Currently the only learning rate scheduler supported is MultiStepLR, specified through the params of `Trainer()` constructor. \r\nWhat do you think about a more flexible approach for lr scheduler, maybe an optional user defined function in `Trainer()` similar to `configure_optimizer`?", "closed_by": {"login": "williamFalcon", "id": 3640001, "node_id": "MDQ6VXNlcjM2NDAwMDE=", "avatar_url": "https://avatars.githubusercontent.com/u/3640001?v=4", "gravatar_id": "", "url": "https://api.github.com/users/williamFalcon", "html_url": "https://github.com/williamFalcon", "followers_url": "https://api.github.com/users/williamFalcon/followers", "following_url": "https://api.github.com/users/williamFalcon/following{/other_user}", "gists_url": "https://api.github.com/users/williamFalcon/gists{/gist_id}", "starred_url": "https://api.github.com/users/williamFalcon/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/williamFalcon/subscriptions", "organizations_url": "https://api.github.com/users/williamFalcon/orgs", "repos_url": "https://api.github.com/users/williamFalcon/repos", "events_url": "https://api.github.com/users/williamFalcon/events{/privacy}", "received_events_url": "https://api.github.com/users/williamFalcon/received_events", "type": "User", "site_admin": false}, "reactions": {"url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/14/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}, "timeline_url": "https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/14/timeline", "performed_via_github_app": null}